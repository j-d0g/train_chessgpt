step 0: train loss 3.5516, val loss 3.5519
iter 0: loss 3.5527, time 15476.42ms, mfu -100.00%
iter 50: loss 2.0293, time 890.74ms, mfu 28.46%
iter 100: loss 1.8278, time 890.52ms, mfu 28.46%
iter 150: loss 1.7291, time 889.75ms, mfu 28.47%
iter 200: loss 1.6706, time 889.76ms, mfu 28.47%
iter 250: loss 1.5988, time 890.72ms, mfu 28.47%
iter 300: loss 1.6029, time 890.82ms, mfu 28.47%
iter 350: loss 1.5031, time 890.85ms, mfu 28.47%
iter 400: loss 1.3667, time 890.05ms, mfu 28.47%
iter 450: loss 1.4149, time 890.55ms, mfu 28.47%
iter 500: loss 1.2637, time 889.68ms, mfu 28.47%
iter 550: loss 1.1955, time 891.16ms, mfu 28.47%
Traceback (most recent call last):
  File "/app/train.py", line 319, in <module>
    scaler.scale(loss).backward()
  File "/opt/conda/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
